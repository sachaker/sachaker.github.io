### *Novemeber 3rd, 2020*
---
# **Reflexivity in politics**
Distributing poll results to a population before an election degrades the predictiveness of that population by a significant margin. Is there a [psephological](https://en.wikipedia.org/wiki/Psephology) law for this? I'm not sure, but there should be...

In 2016, I warned my family and friends that distributing polls that predict a landslide in Clinton's favor would result in mass complacency, and that this complacency would manifest as poor Democractic turnout. If my community of friends is at all a microcosm to the younger population in the United States, in 2016, ~10 of them (likely more—I only asked a small handful) did not vote because "Hilary [was] going to win in a landslide... No need to go through the pain of voting". 3 of those 10 friends were from Florida, a [crucial swing state](https://en.wikipedia.org/wiki/2016_United_States_presidential_election_in_Florida) in that election. I fear that the same thing may happen with this election today.

While I am not confident in the final outcome of this election, I do feel comfortable positing that the final result will be *much* closer than predicted by any leading pollsters.

The point here is that I think that there is a lot about [reflexivity](https://en.wikipedia.org/wiki/Reflexivity_(social_theory)) that remains unexplored and believe that finding elegant ways to mathematically model reflexivity in different systems would be of immeasurable benefit to statistics, economics, neuroscience, and beyond.

> Shockingly, the "error" of the pollsters' predictions in 2016 was actually pretty much at the [mean combined error for past elections](https://fivethirtyeight.com/features/the-polls-are-all-right/) (only 4% higher than the average). It should be noted that these data are weighted by the number of polls put out by each institution and so the most active pollsters are weighted the highest. The interesting insight here would be to see whether there is a correlation between this weight and the error itself, since the most popular pollsters can be expected to be covered by big media outlets more than their counterparts. The more media coverage a poll receives, the less likely it is to be correct.

&nbsp;


### *May 12th, 2020*
---
# **Why we need to put the breaks on longevity research**



### *May 27th, 2020*
---
# **On progress**

[Patrick Collison](https://patrickcollison.com/) and [Tyler Cowen](https://en.wikipedia.org/wiki/Tyler_Cowen) made waves with their arguably seminal article "[We Need a Need Science of Progress](https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/)". In this article, they outline the stagnation in progress across various industries and the dire need to establish heurestics for tracking their respective progresses. What was so curious about the article's success was the fact that it took so long for anyone to really voice this almost obvious solution.

Perhaps since the dawn of civilization there have existed dissenting groups that point at societal frameworks and expose their shortcomings, particularly in their ability to enact positive change or progress. Ironically, I am not aware of any notable expositions (like the Collison-Cowen article) that explicitly express the need to systematically enforce the tracking of progress itself. 

Now there are many important considerations for defining progress that I believe are requisite for the actual implementation of "Progress Studies". Here are some early ones that come to mind:

- Should we consider progress to be relative or absolute? If relative, then to what?
- How do we start to build metrics that can accurately assess progress and how can we further develop metrics that track the usability of progress metrics?
- 

On the first of these points, I believe that an absolute measure is an absolute necessity. [Ray Dalio](https://en.wikipedia.org/wiki/Ray_Dalio) once said "If you look back on yourself [in a year] and don't think you were dumb then, you mustn't have learned much", and this is an interesting proposal for a relative system of progress. What would happen if we measure progress by that which we have achieved relative to the previous year (assuming we have faithful metrics for progress)? This happens all the time with public companies—investors need to see positive and increasing YTD growth or else the company is considered stagnant. I think, when it comes to industries or non-private institutions, metrics with such a short time scale would prove too volatile and probably the comparison date or averaging window should be catered to each industry—a rolling window of about 5 years seems reasonable for academic institutions, for instance.

On the second, this will likely prove to be the hardest of them all. Defining growth is incredibly difficult despite the illusion that there are actual metrics for doing so.



&nbsp;
